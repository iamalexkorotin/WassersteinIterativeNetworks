{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src import distributions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.resnet2 import ResNet_G\n",
    "from src.unet import UNet\n",
    "from src.tools import h5py_to_dataset\n",
    "\n",
    "from src.tools import freeze\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_IDS = [0,1,2,3]\n",
    "\n",
    "# DATASET, DATASET_PATH = 'ave_celeba', '../../data/ave_celeba/'\n",
    "# DATASET, DATASET_PATH = 'celeba', '../../data/celeba_aligned/' # 202k Celeba Images resized to 64x64\n",
    "# DATASET, DATASET_PATH = 'mnist01', '../../data/'\n",
    "# DATASET, DATASET_PATH = 'fashionmnist_all', '../../data/'\n",
    "# DATASET, DATASET_PATH = 'fashionmnist017', '../../data/'\n",
    "DATASET, DATASET_PATH = 'handbag_shoes_fruit360', '../../data/' # shoes, handbags, fruit360\n",
    "\n",
    "SHIFT = True if DATASET == 'ave_celeba' else False # Preprocess the data with shifting means?\n",
    "INPUT_PATH = '../checkpoints/{}/'.format(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
    "\n",
    "if DATASET == 'ave_celeba':\n",
    "    IMG_SIZE, SIZE, NC, Z_DIM = 64, 200000, 3, 128\n",
    "    ALPHAS = [0.25, 0.5, 0.25]\n",
    "    CLASSES = [0, 1, 2]\n",
    "elif DATASET == 'celeba':\n",
    "    IMG_SIZE, SIZE, NC, Z_DIM = 64, 200000, 3, 128\n",
    "    ALPHAS = [1.]\n",
    "    CLASSES = [0]\n",
    "elif DATASET == 'fashionmnist_all':\n",
    "    IMG_SIZE, SIZE, NC, Z_DIM = 32, 6000, 1, 16\n",
    "    ALPHAS = [0.1 for _ in range(10)]\n",
    "    CLASSES = list(range(10))\n",
    "elif DATASET == 'fashionmnist017':\n",
    "    IMG_SIZE, SIZE, NC, Z_DIM = 32, 6000, 1, 16\n",
    "    ALPHAS = [1/3. for _ in range(3)]\n",
    "    CLASSES = [0,1,7]\n",
    "elif DATASET == 'mnist01':\n",
    "    IMG_SIZE, SIZE, NC, Z_DIM = 32, 6000, 1, 16\n",
    "    ALPHAS = [0.5, .5]\n",
    "    CLASSES = [0,1]\n",
    "elif DATASET == 'handbag_shoes_fruit360':\n",
    "    IMG_SIZE, SIZE, NC, Z_DIM = 64, 6000, 3, 128\n",
    "    ALPHAS = [1./3, 1./3, 1./3]\n",
    "    CLASSES = None\n",
    "else:\n",
    "    raise Exception('Unknown dataset')\n",
    "    \n",
    "K = len(ALPHAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Samplers (Z, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_sampler = distributions.StandardNormalSampler(dim=Z_DIM)\n",
    "Y_samplers = []\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(14, fill=(255,255,255)) if DATASET == 'handbag_shoes_fruit360' else torchvision.transforms.Lambda(lambda x:x),\n",
    "    torchvision.transforms.Resize(IMG_SIZE),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x: 2 * x - 1)\n",
    "])\n",
    "\n",
    "if DATASET != 'handbag_shoes_fruit360': \n",
    "    for k in range(K):\n",
    "        if DATASET in ['ave_celeba', 'celeba']:\n",
    "            dataset = torchvision.datasets.ImageFolder(DATASET_PATH, transform=transform)\n",
    "        elif 'fashionmnist' in DATASET:\n",
    "            dataset = torchvision.datasets.FashionMNIST(root=DATASET_PATH, download=True, transform=transform, train=True)\n",
    "        elif 'mnist' in DATASET:\n",
    "            dataset = torchvision.datasets.MNIST(root=DATASET_PATH, download=True, transform=transform)\n",
    "        else:\n",
    "            raise Exception('Unknown dataset')\n",
    "\n",
    "        try:\n",
    "            dataset.samples = [s for s in dataset.samples if s[1] == CLASSES[k]]\n",
    "        except:\n",
    "            idx = [t == CLASSES[k] for t in dataset.targets]\n",
    "            if 'mnist' in DATASET:\n",
    "                dataset.targets, dataset.data = np.array(dataset.targets)[idx], torch.tensor(dataset.data)[idx]\n",
    "            else:\n",
    "                dataset.targets, dataset.data = np.array(dataset.targets)[idx], np.array(dataset.data)[idx]\n",
    "\n",
    "        Y_samplers.append(distributions.DatasetSampler(dataset))\n",
    "        \n",
    "elif DATASET == 'handbag_shoes_fruit360':\n",
    "    dataset = h5py_to_dataset(os.path.join(DATASET_PATH, 'handbag_64.hdf5'))\n",
    "    Y_samplers.append(distributions.DatasetSampler(dataset))\n",
    "    dataset = h5py_to_dataset(os.path.join(DATASET_PATH, 'shoes_64.hdf5'))\n",
    "    Y_samplers.append(distributions.DatasetSampler(dataset))\n",
    "    dataset = torchvision.datasets.ImageFolder(os.path.join(DATASET_PATH, 'fruit360'), transform=transform)\n",
    "    Y_samplers.append(distributions.DatasetSampler(dataset))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    Y_bar_mean = 0.\n",
    "    Y_means = []\n",
    "    for k in range(K):\n",
    "        Y_means.append(Y_samplers[k].dataset.mean(dim=0))\n",
    "        Y_bar_mean += ALPHAS[k] * Y_means[-1]\n",
    "    Y_shifts = [(Y_means[k] - Y_bar_mean).cuda() for k in range(K)]\n",
    "        \n",
    "    if SHIFT:\n",
    "        for k in range(K):\n",
    "            Y_samplers[k].dataset += Y_bar_mean - Y_means[k]\n",
    "    \n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ResNet_G(Z_DIM, IMG_SIZE, nc=NC).cuda()\n",
    "\n",
    "Ts, Ts_inv = [], []\n",
    "for k in range(K):\n",
    "    Ts.append(UNet(NC, NC, base_factor=48 if NC == 3 else 16).cuda())\n",
    "    if DATASET != 'celeba':\n",
    "        Ts_inv.append(UNet(NC, NC, base_factor=48 if NC == 3 else 16).cuda()) \n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    G = nn.DataParallel(G, device_ids=DEVICE_IDS)\n",
    "    for k in range(K):\n",
    "        Ts[k] = nn.DataParallel(Ts[k], device_ids=DEVICE_IDS)\n",
    "        if DATASET != 'celeba':\n",
    "            Ts_inv[k] = nn.DataParallel(Ts_inv[k], device_ids=DEVICE_IDS)\n",
    "\n",
    "G.load_state_dict(torch.load(os.path.join('../checkpoints/{}/'.format(DATASET), 'G.pt')))\n",
    "for k in range(K):\n",
    "    Ts[k].load_state_dict(torch.load(os.path.join('../checkpoints/{}/'.format(DATASET), f'T_{k}.pt')))\n",
    "    if DATASET != 'celeba':\n",
    "        Ts_inv[k].load_state_dict(torch.load(os.path.join('../checkpoints/{}/'.format(DATASET), f'T_inv_{k}.pt')))\n",
    "\n",
    "freeze(G)\n",
    "for k in range(K):\n",
    "    freeze(Ts[k]);\n",
    "    if DATASET != 'celeba':\n",
    "        freeze(Ts_inv[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "Z = Z_sampler.sample(12)\n",
    "with torch.no_grad():\n",
    "    X = G(Z)\n",
    "    Ys = [Y_samplers[k].sample(12) for k in range(K)]\n",
    "#     Ys = [Y_samplers[k].dataset[:12].cuda() for k in range(K)]\n",
    "    Ts_X = [Ts[k](X) for k in range(K)]\n",
    "    if DATASET != 'celeba':\n",
    "        Ts_inv_Y = [Ts_inv[k](Ys[k]) for k in range(K)]\n",
    "    \n",
    "    if SHIFT:\n",
    "        for k in range(K):\n",
    "            Ts_X[k] += Y_shifts[k]\n",
    "            Ys[k] += Y_shifts[k]\n",
    "    \n",
    "    X_avg = 0.\n",
    "    for k in range(K):\n",
    "        X_avg += Ts_X[k] * ALPHAS[k]\n",
    "    \n",
    "    Ts_inv_Y_base = [Ys[k] - Y_shifts[k] for k in range(K)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated images and maps to marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(K+2, 12, figsize=(26.5, 2 * (K+2)),dpi=200)\n",
    "imgs = torch.cat([X] + [Ts_X[k] for k in range(K)] + [X_avg]).to('cpu').add(1).mul(0.5).permute(0, 2, 3, 1).detach().numpy().clip(0,1)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(imgs[i], cmap=plt.get_cmap('gray').reversed() if NC == 1 else None)\n",
    "\n",
    "axes[0,0].set_ylabel(r'$\\mathbb{P}_{\\xi}\\!=\\!G_{\\xi}\\sharp\\mathbb{S}$', fontsize=38, rotation='horizontal', va=\"center\", labelpad=95) #, color='limegreen')\n",
    "axes[-1,0].set_ylabel(r'$\\approx\\mathcal{H}(\\mathbb{P}_{\\xi})$', fontsize=38, rotation='horizontal', va=\"center\", labelpad=95) #, color='limegreen')\n",
    "for k in range(K):\n",
    "    title = '$\\\\mathbb{P}_{\\\\xi}\\\\rightarrow\\\\mathbb{P}_{' + str(k+1) + '}$'\n",
    "    axes[k+1,0].set_ylabel(r'{}'.format(title), fontsize=38, rotation='horizontal', va=\"center\", labelpad=95)\n",
    "    \n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "fig.tight_layout(pad=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps from marginals to the barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert DATASET != 'celeba'\n",
    "for k in range(K):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(8.3, 6),dpi=200)\n",
    "    imgs = torch.cat([Ys[k][:3], Ts_inv_Y_base[k][:3], Ts_inv_Y[k][:3]])\n",
    "    imgs = imgs.to('cpu').add(1).mul(0.5).permute(0, 2, 3, 1).detach().numpy().clip(0,1)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(imgs[i], plt.get_cmap('gray').reversed() if NC == 1 else None)\n",
    "        \n",
    "    axes[0,0].set_ylabel(r'$\\mathbb{P}$' + f'$_{{{k+1}}}$', fontsize=38, rotation='horizontal', va=\"center\", labelpad=95)\n",
    "    axes[1,0].set_ylabel(r'$\\lfloor$' + 'CS' + r'$\\rceil$' + '\\n' + r'$\\mathbb{P}$' + f'$_{{{k+1}}}$' + r'$\\rightarrow\\mathbb{P}_{\\xi}$', fontsize=38, rotation='horizontal', va=\"center\", labelpad=95)#, color='gray')\n",
    "    axes[2,0].set_ylabel('Our' + '\\n' + r'$\\mathbb{P}$' + f'$_{{{k+1}}}$' + r'$\\rightarrow\\mathbb{P}_{\\xi}$', fontsize=38, rotation='horizontal', va=\"center\", labelpad=95) #, color='limegreen')\n",
    "\n",
    "            \n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig.tight_layout(pad=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps through the barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert DATASET != 'celeba'\n",
    "idx = 0 # Index of the image to push\n",
    "fig, axes = plt.subplots(K, K+2, figsize=(2*K+4+1.6, 2*K+0.7),dpi=200)\n",
    "imgs = []\n",
    "for k1 in range(K):\n",
    "    with torch.no_grad():\n",
    "        imgs.append(Ys[k1][idx][None])\n",
    "        imgs.append(Ts_inv_Y[k1][idx][None])\n",
    "        for k2 in range(K):\n",
    "            if SHIFT:\n",
    "                imgs.append(Ts[k2](Ts_inv_Y[k1][idx][None]) + Y_shifts[k2])\n",
    "            else:\n",
    "                imgs.append(Ts[k2](Ts_inv_Y[k1][idx][None]))\n",
    "\n",
    "imgs = torch.cat(imgs).to('cpu').add(1).mul(0.5).permute(0, 2, 3, 1).detach().numpy().clip(0,1)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(imgs[i], cmap=plt.get_cmap('gray').reversed() if NC == 1 else None)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_title(r'$\\mathbb{P}_{n}$', fontsize=37, rotation='horizontal', va=\"center\", pad=25)\n",
    "axes[0, 1].set_title(r'$\\mathbb{P}_{n}\\rightarrow\\mathbb{P}_{\\xi}$', fontsize=37, rotation='horizontal', va=\"center\", pad=25)\n",
    "\n",
    "for k in range(K):\n",
    "    axes[k, 0].set_ylabel(r'$n=$' + str(k+1), fontsize=37, rotation='horizontal', va=\"center\", labelpad=65)\n",
    "    title_1 = '$\\\\mathbb{P}_{\\\\xi}\\\\rightarrow\\\\mathbb{P}_{' + str(k+1) + '}}$'\n",
    "    axes[0, k+2].set_title(r'{}'.format(title_1), fontsize=37, rotation='horizontal', va=\"center\", pad=25)\n",
    "fig.tight_layout(pad=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps through the barycenter v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert DATASET != 'celeba'\n",
    "for k in range(K):\n",
    "    fig, axes = plt.subplots(2+K, 3, figsize=(8.3, 2*(2+K)),dpi=200)\n",
    "    imgs = torch.cat([Ys[k][:3], Ts_inv_Y[k][:3], *[Ts[k2](Ts_inv_Y[k][:3])  + Y_shifts[k2] for k2 in range(K)]])\n",
    "    imgs = imgs.to('cpu').add(1).mul(0.5).permute(0, 2, 3, 1).detach().numpy().clip(0,1)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(imgs[i], plt.get_cmap('gray').reversed() if NC == 1 else None)\n",
    "        \n",
    "    axes[0,0].set_ylabel(r'$\\mathbb{P}$' + f'$_{{{k+1}}}$', fontsize=38, rotation='horizontal', va=\"center\", labelpad=95)\n",
    "    axes[1,0].set_ylabel(r'$\\mathbb{P}$' + f'$_{{{k+1}}}$' + r'$\\rightarrow\\mathbb{P}_{\\xi}$', rotation='horizontal', fontsize=38, va=\"center\", labelpad=95)\n",
    "    for k2 in range(K):\n",
    "        axes[k2+2,0].set_ylabel(\n",
    "            r'$\\mathbb{P}$' + f'$_{{{k+1}}}$' + r'$\\rightarrow\\mathbb{P}_{\\xi}$' + '\\n' +\n",
    "            r'$\\mathbb{P}_{\\xi}$' + r'$\\rightarrow\\mathbb{P}$' + f'$_{{{k2+1}}}$',\n",
    "            rotation='horizontal', fontsize=38, va=\"center\", labelpad=95)\n",
    "        \n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig.tight_layout(pad=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
